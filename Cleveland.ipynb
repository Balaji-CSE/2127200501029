{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMf7VIowKHyLUWwn9l/khEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balaji-CSE/2127200501029/blob/main/Cleveland.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dZimMwyr5f4L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "import statistics\n",
        "\n",
        "df = pd.read_csv(\"cleveland_ds.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA CLEANING Filling missing vales with mode values\n",
        "\n",
        "import statistics\n",
        "needs_to_clean = ['ca', 'thal']\n",
        "for i in needs_to_clean:\n",
        "    X = df[i].values\n",
        "    data = np.array(X)\n",
        "    mode_result = statistics.mode(data)\n",
        "    df[i] = df[i].replace('?', mode_result)\n",
        "    print(\"Mode:\", mode_result)\n",
        "\n",
        "vandhu = ['target']\n",
        "\n",
        "#Standardizing target variable...\n",
        "df.loc[df['target'] > 0, 'target'] = 1"
      ],
      "metadata": {
        "id": "CJyPB7cOd9jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574d4b4d-6e33-46f9-c775-87fb7226fb48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode: 0.0\n",
            "Mode: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting into features and class label\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X = df.drop('target',axis = 1)\n",
        "y = df['target']\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 23)\n",
        "scaler  = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "HuMfB9lfy6v6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN Classifier\n",
        "\n"
      ],
      "metadata": {
        "id": "grKKMJZnHiHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "knn = KNeighborsClassifier(n_neighbors=11)\n",
        "knn.fit(X_train,y_train)\n",
        "knnpred = knn.predict(X_test)\n",
        "accuracy = round(accuracy_score(y_test, knnpred)*100,2)\n",
        "print(\"Accuracy = \",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7T6XQcy09UV",
        "outputId": "f4f511fe-acea-46a0-e2c6-df0cfe04f879"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  85.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EMPTY"
      ],
      "metadata": {
        "id": "ymnzMTrxNN2f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvscore = cross_val_score(KNeighborsClassifier(n_neighbors=11),X,y,cv = 10)\n",
        "cvscore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTWIzm_n1riq",
        "outputId": "da5e45e5-6a62-4fd4-e9f6-d100148a4927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.67741935, 0.61290323, 0.58064516, 0.73333333, 0.8       ,\n",
              "       0.53333333, 0.6       , 0.83333333, 0.6       , 0.7       ])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Fold Cross Validation (10fold)"
      ],
      "metadata": {
        "id": "Ml8wQm7twwsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    classifier = KNeighborsClassifier(n_neighbors=11)\n",
        "    classifier.fit(X_train_fold, y_train_fold)\n",
        "    y_pred_fold = classifier.predict(X_test_fold)\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, y_pred_fold) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "mean_accuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", mean_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khxxR-XZwvu4",
        "outputId": "06854822-5cf1-4bf9-ee3c-9a8b70a8fbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 64.51612903225806\n",
            "Confusion Matrix for Fold:\n",
            "[[12  4]\n",
            " [ 7  8]]\n",
            "Accuracy for this fold: 67.74193548387096\n",
            "Confusion Matrix for Fold:\n",
            "[[14  4]\n",
            " [ 6  7]]\n",
            "Accuracy for this fold: 64.51612903225806\n",
            "Confusion Matrix for Fold:\n",
            "[[10  7]\n",
            " [ 4 10]]\n",
            "Accuracy for this fold: 63.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[12  5]\n",
            " [ 6  7]]\n",
            "Accuracy for this fold: 73.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[13  1]\n",
            " [ 7  9]]\n",
            "Accuracy for this fold: 63.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[12  7]\n",
            " [ 4  7]]\n",
            "Accuracy for this fold: 63.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[11  6]\n",
            " [ 5  8]]\n",
            "Accuracy for this fold: 63.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[12  3]\n",
            " [ 8  7]]\n",
            "Accuracy for this fold: 63.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[13  6]\n",
            " [ 5  6]]\n",
            "Accuracy for this fold: 53.333333333333336\n",
            "Confusion Matrix for Fold:\n",
            "[[ 6  6]\n",
            " [ 8 10]]\n",
            "Mean Accuracy = 64.01075268817205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Classifier\n"
      ],
      "metadata": {
        "id": "XZZsYvF7HpbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "\n",
        "Svm = SVC(kernel = 'linear',C=2,probability=True)\n",
        "Svm.fit(X_train,y_train)\n",
        "Svmpred = Svm.predict(X_test)\n",
        "cm = confusion_matrix(y_test,Svmpred)\n",
        "print(cm)\n",
        "accuracy = round(accuracy_score(y_test, Svmpred)*100,2)\n",
        "print(\"Accuracy = \",accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9vUiPRH1x36",
        "outputId": "65d71124-eed8-44b3-f38d-c3ec8452dfa4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[26  7]\n",
            " [ 6 22]]\n",
            "Accuracy =  78.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree\n"
      ],
      "metadata": {
        "id": "z3rqDHzOHmbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DT\n",
        "\n",
        "dt = DecisionTreeClassifier(criterion='entropy',random_state = 23,max_depth=4)\n",
        "dt.fit(X_train,y_train)\n",
        "dtpred = dt.predict(X_test)\n",
        "accuracy = round(accuracy_score(y_test, dtpred)*100,2)\n",
        "print(\"Accuracy = \",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kIAYVU06B5G",
        "outputId": "45290b23-7de4-46cd-e900-73a4e2a7c829"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  78.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "k = 10  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=23)\n",
        "\n",
        "total_accuracy = 0\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    classifier =DecisionTreeClassifier(criterion='entropy',random_state = 23,max_depth=4)\n",
        "    classifier.fit(X_train_fold, y_train_fold)\n",
        "    y_pred_fold = classifier.predict(X_test_fold)\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
        "    fold_accuracy = accuracy_score(y_test_fold, y_pred_fold) * 100\n",
        "    print('Accuracy for this fold:', fold_accuracy)\n",
        "    total_accuracy += fold_accuracy\n",
        "    print(\"Confusion Matrix for Fold:\")\n",
        "    print(cm)\n",
        "\n",
        "mean_accuracy = total_accuracy / k\n",
        "print(\"Mean Accuracy =\", mean_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnh5de3h224Y",
        "outputId": "4235a43b-129e-40aa-c9de-38f5b44c46dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 77.41935483870968\n",
            "Confusion Matrix for Fold:\n",
            "[[14  2]\n",
            " [ 5 10]]\n",
            "Accuracy for this fold: 80.64516129032258\n",
            "Confusion Matrix for Fold:\n",
            "[[16  2]\n",
            " [ 4  9]]\n",
            "Accuracy for this fold: 70.96774193548387\n",
            "Confusion Matrix for Fold:\n",
            "[[12  5]\n",
            " [ 4 10]]\n",
            "Accuracy for this fold: 83.33333333333334\n",
            "Confusion Matrix for Fold:\n",
            "[[15  2]\n",
            " [ 3 10]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[10  4]\n",
            " [ 5 11]]\n",
            "Accuracy for this fold: 86.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[18  1]\n",
            " [ 3  8]]\n",
            "Accuracy for this fold: 70.0\n",
            "Confusion Matrix for Fold:\n",
            "[[12  5]\n",
            " [ 4  9]]\n",
            "Accuracy for this fold: 76.66666666666667\n",
            "Confusion Matrix for Fold:\n",
            "[[12  3]\n",
            " [ 4 11]]\n",
            "Accuracy for this fold: 80.0\n",
            "Confusion Matrix for Fold:\n",
            "[[16  3]\n",
            " [ 3  8]]\n",
            "Accuracy for this fold: 73.33333333333333\n",
            "Confusion Matrix for Fold:\n",
            "[[11  1]\n",
            " [ 7 11]]\n",
            "Mean Accuracy = 76.90322580645162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train,y_train)\n",
        "nbpred = nb.predict(X_test)\n",
        "print(\"Accuracy of NB = \" , accuracy_score(y_test,nbpred)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je48Pzym7XmF",
        "outputId": "3647f7d2-0865-4b52-dcd0-52e8295cd63f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of NB =  81.9672131147541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3IN531A7xCC",
        "outputId": "1fee7fe5-7e24-4071-eab5-15744f1854ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep Learning Model\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "d1 = Dense(units=100, activation='relu')(input_layer)\n",
        "d2 = Dense(units=100, activation='relu')(d1)\n",
        "d3 = Dense(units=100, activation='relu')(d2)\n",
        "d4 = Dense(units=100, activation='relu')(d3)\n",
        "d5 = Dense(units=100, activation='relu')(d4)\n",
        "d6 = Dense(units=100, activation='relu')(d5)\n",
        "d7 = Dense(units=100, activation='relu')(d6)\n",
        "d8 = Dense(units=100, activation='relu')(d7)\n",
        "# d9 = Dense(units=100, activation='relu')(d8)\n",
        "output_layer = Dense(units=1, activation='sigmoid')(d8)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model with metrics and optimizer\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Recall(name=\"Sensitivity\"),\n",
        "             tf.keras.metrics.SpecificityAtSensitivity(0.5, name=\"Specificity\"),\n",
        "             tfa.metrics.F1Score(num_classes=1, threshold=0.5)],\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x=X_train, y=y_train, batch_size=2, epochs=120)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy, sensitivity, specificity, f1_score = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n",
        "print(\"x=\" + str(list(map('{:.2f}%'.format,f1_score))))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2gfYWZC7pOi",
        "outputId": "11910b62-ade4-41e1-aa92-e5e74dfea121"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "121/121 [==============================] - 6s 7ms/step - loss: 0.5142 - accuracy: 0.7479 - Sensitivity: 0.6937 - Specificity: 0.9313 - f1_score: 0.7163\n",
            "Epoch 2/120\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.3524 - accuracy: 0.8554 - Sensitivity: 0.8018 - Specificity: 0.9771 - f1_score: 0.8357\n",
            "Epoch 3/120\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.8719 - Sensitivity: 0.8378 - Specificity: 1.0000 - f1_score: 0.8571\n",
            "Epoch 4/120\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2666 - accuracy: 0.8967 - Sensitivity: 0.8649 - Specificity: 0.9924 - f1_score: 0.8848\n",
            "Epoch 5/120\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.2579 - accuracy: 0.8884 - Sensitivity: 0.8468 - Specificity: 1.0000 - f1_score: 0.8744\n",
            "Epoch 6/120\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.2266 - accuracy: 0.9091 - Sensitivity: 0.8559 - Specificity: 1.0000 - f1_score: 0.8962\n",
            "Epoch 7/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9256 - Sensitivity: 0.9009 - Specificity: 1.0000 - f1_score: 0.9174\n",
            "Epoch 8/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1529 - accuracy: 0.9421 - Sensitivity: 0.9279 - Specificity: 1.0000 - f1_score: 0.9364\n",
            "Epoch 9/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9421 - Sensitivity: 0.9189 - Specificity: 1.0000 - f1_score: 0.9358\n",
            "Epoch 10/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9752 - Sensitivity: 0.9730 - Specificity: 1.0000 - f1_score: 0.9730\n",
            "Epoch 11/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9504 - Sensitivity: 0.9369 - Specificity: 1.0000 - f1_score: 0.9455\n",
            "Epoch 12/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9587 - Sensitivity: 0.9459 - Specificity: 1.0000 - f1_score: 0.9545\n",
            "Epoch 13/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9959 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 0.9955\n",
            "Epoch 14/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9463 - Sensitivity: 0.9369 - Specificity: 1.0000 - f1_score: 0.9412\n",
            "Epoch 15/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9793 - Sensitivity: 0.9730 - Specificity: 0.9924 - f1_score: 0.9774\n",
            "Epoch 16/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9835 - Sensitivity: 0.9910 - Specificity: 1.0000 - f1_score: 0.9821\n",
            "Epoch 17/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 18/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.7153e-04 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 19/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8590e-04 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 20/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.0426e-04 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 21/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 7.0629e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 22/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 5.1765e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 23/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.8940e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 24/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.0335e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 25/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 2.4064e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 26/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.9210e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 27/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5617e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 28/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2960e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 29/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.0902e-05 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 30/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 9.2686e-06 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 31/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 7.4469e-06 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 32/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 5.3354e-06 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 33/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.4576e-06 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 34/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.0543e-06 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 35/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.3298e-06 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 36/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 8.9560e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 37/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 6.4292e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 38/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 4.6912e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 39/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.5654e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 40/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.7382e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 41/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1483e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 42/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 1.7265e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 43/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 1.4132e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 44/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 1.1694e-07 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 45/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 9.7205e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 46/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 8.2939e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 47/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 7.0434e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 48/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 6.0382e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 49/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 5.2485e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 50/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 4.5804e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 51/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 4.0236e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 52/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.5543e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 53/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.1642e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 54/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.8124e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 55/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.5240e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 56/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2704e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 57/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.0448e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 58/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8495e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 59/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.6846e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 60/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5368e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 61/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4051e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 62/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2897e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 63/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1843e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 64/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.0936e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 65/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.0103e-08 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 66/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 9.3537e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 67/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 8.6585e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 68/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 8.0112e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 69/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 7.4455e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 70/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 6.9234e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 71/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 6.5004e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 72/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 6.0698e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 73/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 5.6586e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 74/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 5.3358e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 75/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 4.9983e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 76/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 4.6952e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 77/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 4.4148e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 78/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 4.1369e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 79/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.8975e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 80/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 3.6751e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 81/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 3.4479e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 82/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 3.2572e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 83/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.0679e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 84/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.9015e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 85/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7129e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 86/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.5664e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 87/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.4582e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 88/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 2.3472e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 89/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2434e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 90/120\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 2.1449e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 91/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.0453e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 92/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.9393e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 93/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8455e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 94/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7542e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 95/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.6717e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 96/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5971e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 97/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5328e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 98/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4791e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 99/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4066e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 100/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3486e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 101/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2892e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 102/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2293e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 103/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1675e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 104/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1167e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 105/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.0723e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 106/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.0308e-09 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 107/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 9.9124e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 108/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 9.5361e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 109/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 9.2102e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 110/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 9.0532e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 111/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 8.8529e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 112/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 8.6692e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 113/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 8.5017e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 114/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 8.2884e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 115/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 8.1835e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 116/120\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 7.9945e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 117/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 7.8024e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 118/120\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 7.5805e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 119/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 7.4787e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "Epoch 120/120\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 7.2459e-10 - accuracy: 1.0000 - Sensitivity: 1.0000 - Specificity: 1.0000 - f1_score: 1.0000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.4349 - accuracy: 0.8689 - Sensitivity: 0.8571 - Specificity: 0.8788 - f1_score: 0.8571\n",
            "Test Accuracy: 86.89%\n",
            "Sensitivity (Recall): 0.86\n",
            "Specificity: 0.88\n",
            "x=['0.86%']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagging Classifier"
      ],
      "metadata": {
        "id": "ohRFc3dJnPi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "base_classifier = DecisionTreeClassifier(random_state=42)\n",
        "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "y_pred = bagging_classifier.predict(X_test)\n",
        "accuracy = round(accuracy_score(y_test, y_pred)*100,2)\n",
        "print(\"Accuracy: \",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBlia6NrGXD2",
        "outputId": "b6baa373-069a-41b4-9f4a-ea57b22b4a95"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  78.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost Classifier\n"
      ],
      "metadata": {
        "id": "XVI_t0EzH38Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "base_classifier = DecisionTreeClassifier(max_depth=6)\n",
        "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "y_pred = adaboost_classifier.predict(X_test)\n",
        "accuracy = round(accuracy_score(y_test, y_pred)*100,2)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkHQEirhIRXl",
        "outputId": "64179b4b-65df-494e-a16b-96fb0619a45a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 85.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QDA"
      ],
      "metadata": {
        "id": "-hMdxVMXH94a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda.fit(X_train, y_train)\n",
        "y_pred = qda.predict(X_test)\n",
        "accuracy = round(accuracy_score(y_test, y_pred)*100,2)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwOICA5iI5wC",
        "outputId": "6d517de2-7e7f-46ab-956d-f217a709b892"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensembling Techniques"
      ],
      "metadata": {
        "id": "6GUrvdydH8xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ENSEMBLING TECHNIQUES\n",
        "\n",
        "estimator = []\n",
        "estimator.append(('SVM', Svm))\n",
        "estimator.append(('DT', dt))\n",
        "estimator.append(('KNN', knn))\n",
        "estimator.append(('QDA', qda))\n",
        "#estimator.append(('NB', nb))\n",
        "estimator.append(('bagging',bagging_classifier))\n",
        "#estimator.append(('boosting',adaboost_classifier))\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "Soft = VotingClassifier(estimators = estimator, voting ='soft')\n",
        "Soft.fit(X_train, y_train)\n",
        "y_pred = Soft.predict(X_test)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy After Ensembling = \" , score*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IitdMf7zLd0e",
        "outputId": "b31710cc-0f52-45ee-dd81-a8dbe8feb611"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[29  4]\n",
            " [ 5 23]]\n",
            "Accuracy After Ensembling =  85.24590163934425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras numpy scikit-learn\n"
      ],
      "metadata": {
        "id": "Bja5i32Fom4W",
        "outputId": "fba5b35c-f9b6-439f-e3ee-c46d7c8080f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    }
  ]
}